@article{openai_gpt-4_2023,
	title = {{GPT}-4 {Technical} {Report}},
	volume = {abs/2303.08774},
	url = {https://doi.org/10.48550/arXiv.2303.08774},
	doi = {10.48550/ARXIV.2303.08774},
	urldate = {2025-01-20},
	journal = {CoRR},
	author = {{OpenAI}},
	year = {2023},
	note = {arXiv: 2303.08774},
}

@article{dubey_llama_2024,
	title = {The {Llama} 3 {Herd} of {Models}},
	volume = {abs/2407.21783},
	url = {https://doi.org/10.48550/arXiv.2407.21783},
	doi = {10.48550/ARXIV.2407.21783},
	urldate = {2025-01-20},
	journal = {CoRR},
	author = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurélien and Gregerson, Austen and Spataru, Ava and Rozière, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Nail, Graeme and Mialon, Grégoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel M. and Misra, Ishan and Evtimov, Ivan and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and Linde, Jelmer van der and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and al, et},
	year = {2024},
	note = {arXiv: 2407.21783},
}


@article{adadi_peeking_2018,
	title = {Peeking {Inside} the {Black}-{Box}: {A} {Survey} on {Explainable} {Artificial} {Intelligence} ({XAI})},
	volume = {6},
	shorttitle = {Peeking {Inside} the {Black}-{Box}},
	doi = {10.1109/ACCESS.2018.2870052},
	journal = {IEEE Access},
	author = {Adadi, Amina and Berrada, Mohammed},
	year = {2018},
	pages = {52138--52160},
}


@article{goodman_european_2017,
	title = {European {Union} {Regulations} on {Algorithmic} {Decision}-{Making} and a "{Right} to {Explanation}"},
	volume = {38},
	url = {https://doi.org/10.1609/aimag.v38i3.2741},
	doi = {10.1609/AIMAG.V38I3.2741},
	number = {3},
	urldate = {2025-01-20},
	journal = {AI Mag.},
	author = {Goodman, Bryce and Flaxman, Seth R.},
	year = {2017},
	pages = {50--57},
	file = {Submitted Version:/Users/ahmed/Zotero/storage/NL5J5WFL/Goodman and Flaxman - 2017 - European Union Regulations on Algorithmic Decision-Making and a Right to Explanation.pdf:application/pdf},
}


@misc{amodei_concrete_2016,
	title = {Concrete {Problems} in {AI} {Safety}},
	url = {http://arxiv.org/abs/1606.06565},
	doi = {10.48550/arXiv.1606.06565},
	abstract = {Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function ("avoiding side effects" and "avoiding reward hacking"), an objective function that is too expensive to evaluate frequently ("scalable supervision"), or undesirable behavior during the learning process ("safe exploration" and "distributional shift"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.},
	urldate = {2025-01-20},
	publisher = {arXiv},
	author = {Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Mané, Dan},
	month = jul,
	year = {2016},
	note = {arXiv:1606.06565 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	annote = {Comment: 29 pages},
	file = {Preprint PDF:/Users/ahmed/Zotero/storage/HRRJPZAZ/Amodei et al. - 2016 - Concrete Problems in AI Safety.pdf:application/pdf;Snapshot:/Users/ahmed/Zotero/storage/PY48BISH/1606.html:text/html},
}

@article{ziems_can_2024,
	title = {Can {Large} {Language} {Models} {Transform} {Computational} {Social} {Science}?},
	volume = {50},
	url = {https://doi.org/10.1162/coli\_a\_00502},
	doi = {10.1162/COLI_A_00502},
	number = {1},
	urldate = {2025-01-20},
	journal = {Comput. Linguistics},
	author = {Ziems, Caleb and Held, William and Shaikh, Omar and Chen, Jiaao and Zhang, Zhehao and Yang, Diyi},
	year = {2024},
	pages = {237--291},
}


@misc{gilpin_explaining_2019,
	title = {Explaining {Explanations}: {An} {Overview} of {Interpretability} of {Machine} {Learning}},
	shorttitle = {Explaining {Explanations}},
	url = {http://arxiv.org/abs/1806.00069},
	doi = {10.48550/arXiv.1806.00069},
	abstract = {There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we provide our definition of explainability and show how it can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.},
	urldate = {2025-01-20},
	publisher = {arXiv},
	author = {Gilpin, Leilani H. and Bau, David and Yuan, Ben Z. and Bajwa, Ayesha and Specter, Michael and Kagal, Lalana},
	month = feb,
	year = {2019},
	note = {arXiv:1806.00069 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: The 5th IEEE International Conference on Data Science and Advanced Analytics (DSAA 2018). [Research Track]},
	file = {Preprint PDF:/Users/ahmed/Zotero/storage/5732XF3K/Gilpin et al. - 2019 - Explaining Explanations An Overview of Interpretability of Machine Learning.pdf:application/pdf},
}


@article{wachter_counterfactual_2017,
	title = {Counterfactual {Explanations} without {Opening} the {Black} {Box}: {Automated} {Decisions} and the {GDPR}},
	volume = {abs/1711.00399},
	shorttitle = {Counterfactual {Explanations} without {Opening} the {Black} {Box}},
	url = {http://arxiv.org/abs/1711.00399},
	urldate = {2025-01-20},
	journal = {CoRR},
	author = {Wachter, Sandra and Mittelstadt, Brent D. and Russell, Chris},
	year = {2017},
	note = {arXiv: 1711.00399},
}



@misc{kaushik_learning_2020,
	title = {Learning the {Difference} that {Makes} a {Difference} with {Counterfactually}-{Augmented} {Data}},
	url = {http://arxiv.org/abs/1909.12434},
	doi = {10.48550/arXiv.1909.12434},
	abstract = {Despite alarm over the reliance of machine learning systems on so-called spurious patterns, the term lacks coherent meaning in standard statistical frameworks. However, the language of causality offers clarity: spurious associations are due to confounding (e.g., a common cause), but not direct or indirect causal effects. In this paper, we focus on natural language processing, introducing methods and resources for training models less sensitive to spurious patterns. Given documents and their initial labels, we task humans with revising each document so that it (i) accords with a counterfactual target label; (ii) retains internal coherence; and (iii) avoids unnecessary changes. Interestingly, on sentiment analysis and natural language inference tasks, classifiers trained on original data fail on their counterfactually-revised counterparts and vice versa. Classifiers trained on combined datasets perform remarkably well, just shy of those specialized to either domain. While classifiers trained on either original or manipulated data alone are sensitive to spurious features (e.g., mentions of genre), models trained on the combined data are less sensitive to this signal. Both datasets are publicly available.},
	urldate = {2025-01-20},
	publisher = {arXiv},
	author = {Kaushik, Divyansh and Hovy, Eduard and Lipton, Zachary C.},
	month = feb,
	year = {2020},
	note = {arXiv:1909.12434 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Published at ICLR 2020},
	file = {Preprint PDF:/Users/ahmed/Zotero/storage/LYS4DTFY/Kaushik et al. - 2020 - Learning the Difference that Makes a Difference with Counterfactually-Augmented Data.pdf:application/pdf;Snapshot:/Users/ahmed/Zotero/storage/F63H8Z8V/1909.html:text/html},
}

@inproceedings{ghandeharioun_patchscopes_2024,
	title = {Patchscopes: {A} {Unifying} {Framework} for {Inspecting} {Hidden} {Representations} of {Language} {Models}},
	shorttitle = {Patchscopes},
	url = {https://openreview.net/forum?id=5uwBzcn885},
	urldate = {2025-01-20},
	booktitle = {Forty-first {International} {Conference} on {Machine} {Learning}, {ICML} 2024, {Vienna}, {Austria}, {July} 21-27, 2024},
	publisher = {OpenReview.net},
	author = {Ghandeharioun, Asma and Caciularu, Avi and Pearce, Adam and Dixon, Lucas and Geva, Mor},
	year = {2024},
}


@misc{pope_text_2021,
	title = {Text {Counterfactuals} via {Latent} {Optimization} and {Shapley}-{Guided} {Search}},
	url = {http://arxiv.org/abs/2110.11589},
	doi = {10.48550/arXiv.2110.11589},
	abstract = {We study the problem of generating counterfactual text for a classifier as a means for understanding and debugging classification. Given a textual input and a classification model, we aim to minimally alter the text to change the model's prediction. White-box approaches have been successfully applied to similar problems in vision where one can directly optimize the continuous input. Optimization-based approaches become difficult in the language domain due to the discrete nature of text. We bypass this issue by directly optimizing in the latent space and leveraging a language model to generate candidate modifications from optimized latent representations. We additionally use Shapley values to estimate the combinatoric effect of multiple changes. We then use these estimates to guide a beam search for the final counterfactual text. We achieve favorable performance compared to recent white-box and black-box baselines using human and automatic evaluations. Ablation studies show that both latent optimization and the use of Shapley values improve success rate and the quality of the generated counterfactuals.},
	urldate = {2025-01-20},
	publisher = {arXiv},
	author = {Pope, Quintin and Fern, Xiaoli Z.},
	month = oct,
	year = {2021},
	note = {arXiv:2110.11589 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: 9 pages, 2 figures, 3 tables. Accepted at EMNLP 2021},
	file = {Preprint PDF:/Users/ahmed/Zotero/storage/9TLIEJHL/Pope and Fern - 2021 - Text Counterfactuals via Latent Optimization and Shapley-Guided Search.pdf:application/pdf;Snapshot:/Users/ahmed/Zotero/storage/UTN52MHE/2110.html:text/html},
}


@misc{wu_polyjuice_2021,
	title = {Polyjuice: {Generating} {Counterfactuals} for {Explaining}, {Evaluating}, and {Improving} {Models}},
	shorttitle = {Polyjuice},
	url = {http://arxiv.org/abs/2101.00288},
	doi = {10.48550/arXiv.2101.00288},
	abstract = {While counterfactual examples are useful for analysis and training of NLP models, current generation methods either rely on manual labor to create very few counterfactuals, or only instantiate limited types of perturbations such as paraphrases or word substitutions. We present Polyjuice, a general-purpose counterfactual generator that allows for control over perturbation types and locations, trained by finetuning GPT-2 on multiple datasets of paired sentences. We show that Polyjuice produces diverse sets of realistic counterfactuals, which in turn are useful in various distinct applications: improving training and evaluation on three different tasks (with around 70\% less annotation effort than manual generation), augmenting state-of-the-art explanation techniques, and supporting systematic counterfactual error analysis by revealing behaviors easily missed by human experts.},
	urldate = {2025-01-20},
	publisher = {arXiv},
	author = {Wu, Tongshuang and Ribeiro, Marco Tulio and Heer, Jeffrey and Weld, Daniel S.},
	month = jun,
	year = {2021},
	note = {arXiv:2101.00288 [cs]},
	keywords = {Computer Science - Computation and Language},
	annote = {Comment: ACL 2021, main conference, long paper},
	file = {Preprint PDF:/Users/ahmed/Zotero/storage/6MAQTX4K/Wu et al. - 2021 - Polyjuice Generating Counterfactuals for Explaining, Evaluating, and Improving Models.pdf:application/pdf;Snapshot:/Users/ahmed/Zotero/storage/C9CVGQJR/2101.html:text/html},
}

@inproceedings{goodfellow_explaining_2015,
	title = {Explaining and {Harnessing} {Adversarial} {Examples}},
	url = {http://arxiv.org/abs/1412.6572},
	urldate = {2025-01-21},
	booktitle = {3rd {International} {Conference} on {Learning} {Representations}, {ICLR} 2015, {San} {Diego}, {CA}, {USA}, {May} 7-9, 2015, {Conference} {Track} {Proceedings}},
	author = {Goodfellow, Ian J. and Shlens, Jonathon and Szegedy, Christian},
	editor = {Bengio, Yoshua and LeCun, Yann},
	year = {2015},
}


@inproceedings{ebrahimi_hotflip_2018,
	title = {{HotFlip}: {White}-{Box} {Adversarial} {Examples} for {Text} {Classification}},
	shorttitle = {{HotFlip}},
	url = {https://aclanthology.org/P18-2006/},
	doi = {10.18653/V1/P18-2006},
	urldate = {2025-01-21},
	booktitle = {Proceedings of the 56th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}, {ACL} 2018, {Melbourne}, {Australia}, {July} 15-20, 2018, {Volume} 2: {Short} {Papers}},
	publisher = {Association for Computational Linguistics},
	author = {Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
	editor = {Gurevych, Iryna and Miyao, Yusuke},
	year = {2018},
	pages = {31--36},
}

@inproceedings{yang_generating_2020,
	title = {Generating {Plausible} {Counterfactual} {Explanations} for {Deep} {Transformers} in {Financial} {Text} {Classification}},
	url = {https://doi.org/10.18653/v1/2020.coling-main.541},
	doi = {10.18653/V1/2020.COLING-MAIN.541},
	urldate = {2025-01-21},
	booktitle = {Proceedings of the 28th {International} {Conference} on {Computational} {Linguistics}, {COLING} 2020, {Barcelona}, {Spain} ({Online}), {December} 8-13, 2020},
	publisher = {International Committee on Computational Linguistics},
	author = {Yang, Linyi and Kenny, Eoin M. and Ng, Tin Lok James and Yang, Yi and Smyth, Barry and Dong, Ruihai},
	editor = {Scott, Donia and Bel, Núria and Zong, Chengqing},
	year = {2020},
	pages = {6150--6160},
	file = {Full Text:/Users/ahmed/Zotero/storage/ES7HND22/Yang et al. - 2020 - Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classificat.pdf:application/pdf},
}


@inproceedings{ross_explaining_2021,
	series = {Findings of {ACL}},
	title = {Explaining {NLP} {Models} via {Minimal} {Contrastive} {Editing} ({MiCE})},
	volume = {ACL/IJCNLP 2021},
	url = {https://doi.org/10.18653/v1/2021.findings-acl.336},
	doi = {10.18653/V1/2021.FINDINGS-ACL.336},
	urldate = {2025-01-21},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics}: {ACL}/{IJCNLP} 2021, {Online} {Event}, {August} 1-6, 2021},
	publisher = {Association for Computational Linguistics},
	author = {Ross, Alexis and Marasovic, Ana and Peters, Matthew E.},
	editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
	year = {2021},
	pages = {3840--3852},
	file = {Full Text:/Users/ahmed/Zotero/storage/57KPE97D/Ross et al. - 2021 - Explaining NLP Models via Minimal Contrastive Editing (MiCE).pdf:application/pdf},
}


@article{lundberg_unified_2017,
	title = {A unified approach to interpreting model predictions},
	volume = {abs/1705.07874},
	url = {http://arxiv.org/abs/1705.07874},
	urldate = {2025-01-22},
	journal = {CoRR},
	author = {Lundberg, Scott M. and Lee, Su-In},
	year = {2017},
	note = {arXiv: 1705.07874},
}

@article{radford_language_2019,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{madaan_generate_2021,
	title = {Generate {Your} {Counterfactuals}: {Towards} {Controlled} {Counterfactual} {Generation} for {Text}},
	shorttitle = {Generate {Your} {Counterfactuals}},
	url = {https://doi.org/10.1609/aaai.v35i15.17594},
	doi = {10.1609/AAAI.V35I15.17594},
	urldate = {2025-01-22},
	booktitle = {Thirty-{Fifth} {AAAI} {Conference} on {Artificial} {Intelligence}, {AAAI} 2021, {Thirty}-{Third} {Conference} on {Innovative} {Applications} of {Artificial} {Intelligence}, {IAAI} 2021, {The} {Eleventh} {Symposium} on {Educational} {Advances} in {Artificial} {Intelligence}, {EAAI} 2021, {Virtual} {Event}, {February} 2-9, 2021},
	publisher = {AAAI Press},
	author = {Madaan, Nishtha and Padhi, Inkit and Panwar, Naveen and Saha, Diptikalyan},
	year = {2021},
	pages = {13516--13524},
	file = {Full Text:/Users/ahmed/Zotero/storage/T7EPAE9B/Madaan et al. - 2021 - Generate Your Counterfactuals Towards Controlled Counterfactual Generation for Text.pdf:application/pdf},
}


@article{belinkov_probing_2022,
	title = {Probing {Classifiers}: {Promises}, {Shortcomings}, and {Advances}},
	volume = {48},
	shorttitle = {Probing {Classifiers}},
	url = {https://doi.org/10.1162/coli\_a\_00422},
	doi = {10.1162/COLI_A_00422},
	number = {1},
	urldate = {2025-01-23},
	journal = {Comput. Linguistics},
	author = {Belinkov, Yonatan},
	year = {2022},
	pages = {207--219},
	file = {Full Text:/Users/ahmed/Zotero/storage/GB5Z34E3/Belinkov - 2022 - Probing Classifiers Promises, Shortcomings, and Advances.pdf:application/pdf},
}

@inproceedings{kohn_whats_2015,
	title = {What's in an {Embedding}? {Analyzing} {Word} {Embeddings} through {Multilingual} {Evaluation}},
	shorttitle = {What's in an {Embedding}?},
	url = {https://doi.org/10.18653/v1/d15-1246},
	doi = {10.18653/V1/D15-1246},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2015, {Lisbon}, {Portugal}, {September} 17-21, 2015},
	publisher = {The Association for Computational Linguistics},
	author = {Köhn, Arne},
	editor = {Màrquez, Lluís and Callison-Burch, Chris and Su, Jian and Pighin, Daniele and Marton, Yuval},
	year = {2015},
	pages = {2067--2073},
	file = {Full Text:/Users/ahmed/Zotero/storage/GW89G9DC/Köhn - 2015 - What's in an Embedding Analyzing Word Embeddings through Multilingual Evaluation.pdf:application/pdf},
}


@inproceedings{gupta_distributional_2015,
	title = {Distributional vectors encode referential attributes},
	url = {https://doi.org/10.18653/v1/d15-1002},
	doi = {10.18653/V1/D15-1002},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2015 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2015, {Lisbon}, {Portugal}, {September} 17-21, 2015},
	publisher = {The Association for Computational Linguistics},
	author = {Gupta, Abhijeet and Boleda, Gemma and Baroni, Marco and Padó, Sebastian},
	editor = {Màrquez, Lluís and Callison-Burch, Chris and Su, Jian and Pighin, Daniele and Marton, Yuval},
	year = {2015},
	pages = {12--21},
	file = {Full Text:/Users/ahmed/Zotero/storage/2DQ36WGU/Gupta et al. - 2015 - Distributional vectors encode referential attributes.pdf:application/pdf},
}

@inproceedings{geiger_causal_2021,
	title = {Causal {Abstractions} of {Neural} {Networks}},
	url = {https://proceedings.neurips.cc/paper/2021/hash/4f5c422f4d49a5a807eda27434231040-Abstract.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 34: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2021, {NeurIPS} 2021, {December} 6-14, 2021, virtual},
	author = {Geiger, Atticus and Lu, Hanson and Icard, Thomas and Potts, Christopher},
	editor = {Ranzato, Marc'Aurelio and Beygelzimer, Alina and Dauphin, Yann N. and Liang, Percy and Vaughan, Jennifer Wortman},
	year = {2021},
	pages = {9574--9586},
}


@inproceedings{stolfo_mechanistic_2023,
	title = {A {Mechanistic} {Interpretation} of {Arithmetic} {Reasoning} in {Language} {Models} using {Causal} {Mediation} {Analysis}},
	url = {https://doi.org/10.18653/v1/2023.emnlp-main.435},
	doi = {10.18653/V1/2023.EMNLP-MAIN.435},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2023 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2023, {Singapore}, {December} 6-10, 2023},
	publisher = {Association for Computational Linguistics},
	author = {Stolfo, Alessandro and Belinkov, Yonatan and Sachan, Mrinmaya},
	editor = {Bouamor, Houda and Pino, Juan and Bali, Kalika},
	year = {2023},
	pages = {7035--7052},
	file = {Full Text:/Users/ahmed/Zotero/storage/LUI7PRLR/Stolfo et al. - 2023 - A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analy.pdf:application/pdf},
}


@inproceedings{wang_interpretability_2023,
	title = {Interpretability in the {Wild}: a {Circuit} for {Indirect} {Object} {Identification} in {GPT}-2 {Small}},
	shorttitle = {Interpretability in the {Wild}},
	url = {https://openreview.net/forum?id=NpsVSN6o4ul},
	urldate = {2025-01-23},
	booktitle = {The {Eleventh} {International} {Conference} on {Learning} {Representations}, {ICLR} 2023, {Kigali}, {Rwanda}, {May} 1-5, 2023},
	publisher = {OpenReview.net},
	author = {Wang, Kevin Ro and Variengien, Alexandre and Conmy, Arthur and Shlegeris, Buck and Steinhardt, Jacob},
	year = {2023},
}


@article{cammarata_thread_2020,
	title = {Thread: {Circuits}},
	volume = {5},
	issn = {2476-0757},
	shorttitle = {Thread},
	url = {https://distill.pub/2020/circuits},
	doi = {10.23915/distill.00024},
	abstract = {What can we learn if we invest heavily in reverse engineering a single neural network?},
	language = {en},
	number = {3},
	urldate = {2025-01-23},
	journal = {Distill},
	author = {Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris and Petrov, Michael and Schubert, Ludwig and Voss, Chelsea and Egan, Ben and Lim, Swee Kiat},
	month = mar,
	year = {2020},
	pages = {e24},
}


@article{nostalgebraist_interpreting_2020,
	title = {interpreting {GPT}: the logit lens},
	shorttitle = {interpreting {GPT}},
	url = {https://www.lesswrong.com/posts/AcKRB8wDpdaN6v6ru/interpreting-gpt-the-logit-lens},
	abstract = {This post relates an observation I've made in my work with GPT-2, which I have not seen made elsewhere. …},
	language = {en},
	urldate = {2025-01-23},
	author = {nostalgebraist},
	month = aug,
	year = {2020},
	file = {Snapshot:/Users/ahmed/Zotero/storage/5AMKD8IA/interpreting-gpt-the-logit-lens.html:text/html},
}


@article{belrose_eliciting_2023,
	title = {Eliciting {Latent} {Predictions} from {Transformers} with the {Tuned} {Lens}},
	volume = {abs/2303.08112},
	url = {https://doi.org/10.48550/arXiv.2303.08112},
	doi = {10.48550/ARXIV.2303.08112},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Belrose, Nora and Furman, Zach and Smith, Logan and Halawi, Danny and Ostrovsky, Igor and McKinney, Lev and Biderman, Stella and Steinhardt, Jacob},
	year = {2023},
	note = {arXiv: 2303.08112},
}


@inproceedings{vig_investigating_2020,
	title = {Investigating {Gender} {Bias} in {Language} {Models} {Using} {Causal} {Mediation} {Analysis}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/92650b2e92217715fe312e6fa7b90d82-Abstract.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 33: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2020, {NeurIPS} 2020, {December} 6-12, 2020, virtual},
	author = {Vig, Jesse and Gehrmann, Sebastian and Belinkov, Yonatan and Qian, Sharon and Nevo, Daniel and Singer, Yaron and Shieber, Stuart M.},
	editor = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria-Florina and Lin, Hsuan-Tien},
	year = {2020},
}


@inproceedings{li_inference-time_2023,
	title = {Inference-{Time} {Intervention}: {Eliciting} {Truthful} {Answers} from a {Language} {Model}},
	shorttitle = {Inference-{Time} {Intervention}},
	url = {http://papers.nips.cc/paper\_files/paper/2023/hash/81b8390039b7302c909cb769f8b6cd93-Abstract-Conference.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 36: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2023, {NeurIPS} 2023, {New} {Orleans}, {LA}, {USA}, {December} 10 - 16, 2023},
	author = {Li, Kenneth and Patel, Oam and Viégas, Fernanda B. and Pfister, Hanspeter and Wattenberg, Martin},
	editor = {Oh, Alice and Naumann, Tristan and Globerson, Amir and Saenko, Kate and Hardt, Moritz and Levine, Sergey},
	year = {2023},
}


@article{ferrando_primer_2024,
	title = {A {Primer} on the {Inner} {Workings} of {Transformer}-based {Language} {Models}},
	volume = {abs/2405.00208},
	url = {https://doi.org/10.48550/arXiv.2405.00208},
	doi = {10.48550/ARXIV.2405.00208},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Ferrando, Javier and Sarti, Gabriele and Bisazza, Arianna and Costa-jussà, Marta R.},
	year = {2024},
	note = {arXiv: 2405.00208},
}


@article{denil_extraction_2014,
	title = {Extraction of {Salient} {Sentences} from {Labelled} {Documents}},
	volume = {abs/1412.6815},
	url = {http://arxiv.org/abs/1412.6815},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Denil, Misha and Demiraj, Alban and Freitas, Nando de},
	year = {2014},
	note = {arXiv: 1412.6815},
}


@inproceedings{holtzman_surface_2021,
	title = {Surface {Form} {Competition}: {Why} the {Highest} {Probability} {Answer} {Isn}'t {Always} {Right}},
	shorttitle = {Surface {Form} {Competition}},
	url = {https://doi.org/10.18653/v1/2021.emnlp-main.564},
	doi = {10.18653/V1/2021.EMNLP-MAIN.564},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2021, {Virtual} {Event} / {Punta} {Cana}, {Dominican} {Republic}, 7-11 {November}, 2021},
	publisher = {Association for Computational Linguistics},
	author = {Holtzman, Ari and West, Peter and Shwartz, Vered and Choi, Yejin and Zettlemoyer, Luke},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	year = {2021},
	pages = {7038--7051},
	file = {Full Text:/Users/ahmed/Zotero/storage/F8RZFH9U/Holtzman et al. - 2021 - Surface Form Competition Why the Highest Probability Answer Isn't Always Right.pdf:application/pdf},
}



@inproceedings{yin_interpreting_2022,
	title = {Interpreting {Language} {Models} with {Contrastive} {Explanations}},
	url = {https://doi.org/10.18653/v1/2022.emnlp-main.14},
	doi = {10.18653/V1/2022.EMNLP-MAIN.14},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2022 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2022, {Abu} {Dhabi}, {United} {Arab} {Emirates}, {December} 7-11, 2022},
	publisher = {Association for Computational Linguistics},
	author = {Yin, Kayo and Neubig, Graham},
	editor = {Goldberg, Yoav and Kozareva, Zornitsa and Zhang, Yue},
	year = {2022},
	pages = {184--198},
	file = {Full Text:/Users/ahmed/Zotero/storage/9HMZRH86/Yin and Neubig - 2022 - Interpreting Language Models with Contrastive Explanations.pdf:application/pdf},
}


@article{karimi_survey_2023,
	title = {A {Survey} of {Algorithmic} {Recourse}: {Contrastive} {Explanations} and {Consequential} {Recommendations}},
	volume = {55},
	shorttitle = {A {Survey} of {Algorithmic} {Recourse}},
	doi = {10.1145/3527848},
	number = {5},
	journal = {ACM Comput. Surv.},
	author = {Karimi, Amir-Hossein and Barthe, Gilles and Schölkopf, Bernhard and Valera, Isabel},
	year = {2023},
	pages = {95:1--95:29},
	file = {Full Text:/Users/ahmed/Zotero/storage/Z7SKNQKQ/Karimi et al. - 2023 - A Survey of Algorithmic Recourse Contrastive Explanations and Consequential Recommendations.pdf:application/pdf},
}


@article{mcaleese_comparative_2024,
	title = {A {Comparative} {Analysis} of {Counterfactual} {Explanation} {Methods} for {Text} {Classifiers}},
	volume = {abs/2411.02643},
	url = {https://doi.org/10.48550/arXiv.2411.02643},
	doi = {10.48550/ARXIV.2411.02643},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {McAleese, Stephen and Keane, Mark T.},
	year = {2024},
	note = {arXiv: 2411.02643},
}


@article{celar_how_2023,
	title = {How people reason with counterfactual and causal explanations for {Artificial} {Intelligence} decisions in familiar and unfamiliar domains},
	volume = {51},
	issn = {1532-5946},
	url = {https://doi.org/10.3758/s13421-023-01407-5},
	doi = {10.3758/s13421-023-01407-5},
	abstract = {Few empirical studies have examined how people understand counterfactual explanations for other people’s decisions, for example, “if you had asked for a lower amount, your loan application would have been approved”. Yet many current Artificial Intelligence (AI) decision support systems rely on counterfactual explanations to improve human understanding and trust. We compared counterfactual explanations to causal ones, i.e., “because you asked for a high amount, your loan application was not approved”, for an AI’s decisions in a familiar domain (alcohol and driving) and an unfamiliar one (chemical safety) in four experiments (n = 731). Participants were shown inputs to an AI system, its decisions, and an explanation for each decision; they attempted to predict the AI’s decisions, or to make their own decisions. Participants judged counterfactual explanations more helpful than causal ones, but counterfactuals did not improve the accuracy of their predictions of the AI’s decisions more than causals (Experiment 1). However, counterfactuals improved the accuracy of participants’ own decisions more than causals (Experiment 2). When the AI’s decisions were correct (Experiments 1 and 2), participants considered explanations more helpful and made more accurate judgements in the familiar domain than in the unfamiliar one; but when the AI’s decisions were incorrect, they considered explanations less helpful and made fewer accurate judgements in the familiar domain than the unfamiliar one, whether they predicted the AI’s decisions (Experiment 3a) or made their own decisions (Experiment 3b). The results corroborate the proposal that counterfactuals provide richer information than causals, because their mental representation includes more possibilities.},
	language = {en},
	number = {7},
	urldate = {2025-01-23},
	journal = {Memory \& Cognition},
	author = {Celar, Lenart and Byrne, Ruth M. J.},
	month = oct,
	year = {2023},
	keywords = {AI decision support systems, Artificial Intelligence, Causals, Counterfactuals, Decisions, Explanations},
	pages = {1481--1496},
	file = {Full Text PDF:/Users/ahmed/Zotero/storage/F5QQQA56/Celar and Byrne - 2023 - How people reason with counterfactual and causal explanations for Artificial Intelligence decisions.pdf:application/pdf},
}


@inproceedings{atanasova_faithfulness_2023,
	title = {Faithfulness {Tests} for {Natural} {Language} {Explanations}},
	url = {https://doi.org/10.18653/v1/2023.acl-short.25},
	doi = {10.18653/V1/2023.ACL-SHORT.25},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 61st {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 2: {Short} {Papers}), {ACL} 2023, {Toronto}, {Canada}, {July} 9-14, 2023},
	publisher = {Association for Computational Linguistics},
	author = {Atanasova, Pepa and Camburu, Oana-Maria and Lioma, Christina and Lukasiewicz, Thomas and Simonsen, Jakob Grue and Augenstein, Isabelle},
	editor = {Rogers, Anna and Boyd-Graber, Jordan L. and Okazaki, Naoaki},
	year = {2023},
	pages = {283--294},
	file = {Full Text:/Users/ahmed/Zotero/storage/LV5XMIDC/Atanasova et al. - 2023 - Faithfulness Tests for Natural Language Explanations.pdf:application/pdf},
}


@inproceedings{parcalabescu_measuring_2024,
	title = {On {Measuring} {Faithfulness} or {Self}-consistency of {Natural} {Language} {Explanations}},
	url = {https://doi.org/10.18653/v1/2024.acl-long.329},
	doi = {10.18653/V1/2024.ACL-LONG.329},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 62nd {Annual} {Meeting} of the {Association} for {Computational} {Linguistics} ({Volume} 1: {Long} {Papers}), {ACL} 2024, {Bangkok}, {Thailand}, {August} 11-16, 2024},
	publisher = {Association for Computational Linguistics},
	author = {Parcalabescu, Letitia and Frank, Anette},
	editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
	year = {2024},
	pages = {6048--6089},
	file = {Submitted Version:/Users/ahmed/Zotero/storage/FZNG96E7/Parcalabescu and Frank - 2024 - On Measuring Faithfulness or Self-consistency of Natural Language Explanations.pdf:application/pdf},
}


@inproceedings{turpin_language_2023,
	title = {Language {Models} {Don}'t {Always} {Say} {What} {They} {Think}: {Unfaithful} {Explanations} in {Chain}-of-{Thought} {Prompting}},
	shorttitle = {Language {Models} {Don}'t {Always} {Say} {What} {They} {Think}},
	url = {http://papers.nips.cc/paper\_files/paper/2023/hash/ed3fea9033a80fea1376299fa7863f4a-Abstract-Conference.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 36: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2023, {NeurIPS} 2023, {New} {Orleans}, {LA}, {USA}, {December} 10 - 16, 2023},
	author = {Turpin, Miles and Michael, Julian and Perez, Ethan and Bowman, Samuel R.},
	editor = {Oh, Alice and Naumann, Tristan and Globerson, Amir and Saenko, Kate and Hardt, Moritz and Levine, Sergey},
	year = {2023},
}


@article{bhattacharjee_zero-shot_2024,
	title = {Zero-shot {LLM}-guided {Counterfactual} {Generation} for {Text}},
	volume = {abs/2405.04793},
	url = {https://doi.org/10.48550/arXiv.2405.04793},
	doi = {10.48550/ARXIV.2405.04793},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Bhattacharjee, Amrita and Moraffah, Raha and Garland, Joshua and Liu, Huan},
	year = {2024},
	note = {arXiv: 2405.04793},
}



@article{mesnard_gemma_2024,
	title = {Gemma: {Open} {Models} {Based} on {Gemini} {Research} and {Technology}},
	volume = {abs/2403.08295},
	shorttitle = {Gemma},
	url = {https://doi.org/10.48550/arXiv.2403.08295},
	doi = {10.48550/ARXIV.2403.08295},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivière, Morgane and Kale, Mihir Sanjay and Love, Juliette and Tafti, Pouya and Hussenot, Léonard and Chowdhery, Aakanksha and Roberts, Adam and Barua, Aditya and Botev, Alex and Castro-Ros, Alex and Slone, Ambrose and Héliou, Amélie and Tacchetti, Andrea and Bulanova, Anna and Paterson, Antonia and Tsai, Beth and Shahriari, Bobak and Lan, Charline Le and Choquette-Choo, Christopher A. and Crepy, Clément and Cer, Daniel and Ippolito, Daphne and Reid, David and Buchatskaya, Elena and Ni, Eric and Noland, Eric and Yan, Geng and Tucker, George and Muraru, George-Cristian and Rozhdestvenskiy, Grigory and Michalewski, Henryk and Tenney, Ian and Grishchenko, Ivan and Austin, Jacob and Keeling, James and Labanowski, Jane and Lespiau, Jean-Baptiste and Stanway, Jeff and Brennan, Jenny and Chen, Jeremy and Ferret, Johan and Chiu, Justin and al, et},
	year = {2024},
	note = {arXiv: 2403.08295},
}

@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}

@misc{wang2019gluemultitaskbenchmarkanalysis,
      title={GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding}, 
      author={Alex Wang and Amanpreet Singh and Julian Michael and Felix Hill and Omer Levy and Samuel R. Bowman},
      year={2019},
      eprint={1804.07461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1804.07461}, 
}


@inproceedings{kaushik_learning_2020,
	title = {Learning {The} {Difference} {That} {Makes} {A} {Difference} {With} {Counterfactually}-{Augmented} {Data}},
	url = {https://openreview.net/forum?id=Sklgs0NFvr},
	urldate = {2025-01-23},
	booktitle = {8th {International} {Conference} on {Learning} {Representations}, {ICLR} 2020, {Addis} {Ababa}, {Ethiopia}, {April} 26-30, 2020},
	publisher = {OpenReview.net},
	author = {Kaushik, Divyansh and Hovy, Eduard H. and Lipton, Zachary Chase},
	year = {2020},
}


@inproceedings{samory_call_2021,
	title = {"{Call} me sexist, but..." : {Revisiting} {Sexism} {Detection} {Using} {Psychological} {Scales} and {Adversarial} {Samples}},
	shorttitle = {"{Call} me sexist, but..."},
	url = {https://ojs.aaai.org/index.php/ICWSM/article/view/18085},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the {Fifteenth} {International} {AAAI} {Conference} on {Web} and {Social} {Media}, {ICWSM} 2021, held virtually, {June} 7-10, 2021},
	publisher = {AAAI Press},
	author = {Samory, Mattia and Sen, Indira and Kohne, Julian and Flöck, Fabian and Wagner, Claudia},
	editor = {Budak, Ceren and Cha, Meeyoung and Quercia, Daniele and Xie, Lexing},
	year = {2021},
	pages = {573--584},
}


@inproceedings{sen_how_2021,
	title = {How {Does} {Counterfactually} {Augmented} {Data} {Impact} {Models} for {Social} {Computing} {Constructs}?},
	url = {https://doi.org/10.18653/v1/2021.emnlp-main.28},
	doi = {10.18653/V1/2021.EMNLP-MAIN.28},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2021 {Conference} on {Empirical} {Methods} in {Natural} {Language} {Processing}, {EMNLP} 2021, {Virtual} {Event} / {Punta} {Cana}, {Dominican} {Republic}, 7-11 {November}, 2021},
	publisher = {Association for Computational Linguistics},
	author = {Sen, Indira and Samory, Mattia and Flöck, Fabian and Wagner, Claudia and Augenstein, Isabelle},
	editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
	year = {2021},
	pages = {325--344},
	file = {Full Text:/Users/ahmed/Zotero/storage/WSG4A5W8/Sen et al. - 2021 - How Does Counterfactually Augmented Data Impact Models for Social Computing Constructs.pdf:application/pdf},
}


@inproceedings{vaswani_attention_2017,
	title = {Attention is {All} you {Need}},
	url = {https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2017, {December} 4-9, 2017, {Long} {Beach}, {CA}, {USA}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	editor = {Guyon, Isabelle and Luxburg, Ulrike von and Bengio, Samy and Wallach, Hanna M. and Fergus, Rob and Vishwanathan, S. V. N. and Garnett, Roman},
	year = {2017},
	pages = {5998--6008},
}


@inproceedings{brown_language_2020,
	title = {Language {Models} are {Few}-{Shot} {Learners}},
	url = {https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html},
	urldate = {2025-01-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 33: {Annual} {Conference} on {Neural} {Information} {Processing} {Systems} 2020, {NeurIPS} 2020, {December} 6-12, 2020, virtual},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	editor = {Larochelle, Hugo and Ranzato, Marc'Aurelio and Hadsell, Raia and Balcan, Maria-Florina and Lin, Hsuan-Tien},
	year = {2020},
}


@inproceedings{devlin_bert_2019,
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	shorttitle = {{BERT}},
	url = {https://doi.org/10.18653/v1/n19-1423},
	doi = {10.18653/V1/N19-1423},
	urldate = {2025-01-23},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {NAACL}-{HLT} 2019, {Minneapolis}, {MN}, {USA}, {June} 2-7, 2019, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	editor = {Burstein, Jill and Doran, Christy and Solorio, Thamar},
	year = {2019},
	pages = {4171--4186},
}


@article{raffel_exploring_2020,
	title = {Exploring the {Limits} of {Transfer} {Learning} with a {Unified} {Text}-to-{Text} {Transformer}},
	volume = {21},
	url = {https://jmlr.org/papers/v21/20-074.html},
	urldate = {2025-01-23},
	journal = {J. Mach. Learn. Res.},
	author = {Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J.},
	year = {2020},
	pages = {140:1--140:67},
}


@misc{colab_transformer_2024,
	title = {Google {Colab}},
	url = {https://colab.research.google.com/github/callummcdougall/ARENA_3.0/blob/main/chapter1_transformer_interp/exercises/part1_transformer_from_scratch/1.1_Transformer_from_Scratch_exercises.ipynb?t=20250106#scrollTo=XGrOk29kjSKt},
	language = {en},
	urldate = {2025-01-23},
}


@misc{nanda_mathematical_nodate,
	title = {A {Mathematical} {Framework} for {Transformer} {Circuits}},
	url = {https://transformer-circuits.pub/2021/framework/index.html#def-privileged-basis},
	urldate = {2025-01-23},
}


@article{haldar_levenshtein_2011,
	title = {Levenshtein {Distance} {Technique} in {Dictionary} {Lookup} {Methods}: {An} {Improved} {Approach}},
	volume = {abs/1101.1232},
	shorttitle = {Levenshtein {Distance} {Technique} in {Dictionary} {Lookup} {Methods}},
	url = {http://arxiv.org/abs/1101.1232},
	urldate = {2025-01-23},
	journal = {CoRR},
	author = {Haldar, Rishin and Mukhopadhyay, Debajyoti},
	year = {2011},
	note = {arXiv: 1101.1232},
}


@article{chou_counterfactuals_2022,
	title = {Counterfactuals and causability in explainable artificial intelligence: {Theory}, algorithms, and applications},
	volume = {81},
	shorttitle = {Counterfactuals and causability in explainable artificial intelligence},
	url = {https://doi.org/10.1016/j.inffus.2021.11.003},
	doi = {10.1016/J.INFFUS.2021.11.003},
	urldate = {2025-01-23},
	journal = {Inf. Fusion},
	author = {Chou, Yu-Liang and Moreira, Catarina and Bruza, Peter and Ouyang, Chun and Jorge, Joaquim},
	year = {2022},
	pages = {59--83},
}


@article{baron_explainable_2023,
	title = {Explainable {AI} and {Causal} {Understanding}: {Counterfactual} {Approaches} {Considered}},
	volume = {33},
	shorttitle = {Explainable {AI} and {Causal} {Understanding}},
	url = {https://doi.org/10.1007/s11023-023-09637-x},
	doi = {10.1007/S11023-023-09637-X},
	number = {2},
	urldate = {2025-01-23},
	journal = {Minds Mach.},
	author = {Baron, Sam},
	year = {2023},
	pages = {347--377},
	file = {Full Text:/Users/ahmed/Zotero/storage/BT6NDBQT/Baron - 2023 - Explainable AI and Causal Understanding Counterfactual Approaches Considered.pdf:application/pdf},
}


@article{miller_explanation_2019,
	title = {Explanation in artificial intelligence: {Insights} from the social sciences},
	volume = {267},
	shorttitle = {Explanation in artificial intelligence},
	url = {https://doi.org/10.1016/j.artint.2018.07.007},
	doi = {10.1016/J.ARTINT.2018.07.007},
	urldate = {2025-01-23},
	journal = {Artif. Intell.},
	author = {Miller, Tim},
	year = {2019},
	pages = {1--38},
}


@article{buijsman_defining_2022,
	title = {Defining {Explanation} and {Explanatory} {Depth} in {XAI}},
	volume = {32},
	url = {https://doi.org/10.1007/s11023-022-09607-9},
	doi = {10.1007/S11023-022-09607-9},
	number = {3},
	urldate = {2025-01-23},
	journal = {Minds Mach.},
	author = {Buijsman, Stefan},
	year = {2022},
	pages = {563--584},
	file = {Full Text:/Users/ahmed/Zotero/storage/C9RXLG22/Buijsman - 2022 - Defining Explanation and Explanatory Depth in XAI.pdf:application/pdf},
}
